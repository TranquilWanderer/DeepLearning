{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a36568f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_parameters_deep\n",
    "import numpy as np\n",
    "def initialize_parameters_deep(layer_dims):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- bias vector of shape (layer_dims[l], 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            # number of layers in the network\n",
    "\n",
    "    for l in range(1, L):\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l - 1]) * 0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l - 1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8f42bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W1': array([[ 0.01788628,  0.0043651 ,  0.00096497, -0.01863493],\n",
      "       [-0.00277388, -0.00354759, -0.00082741, -0.00627001],\n",
      "       [-0.00043818, -0.00477218, -0.01313865,  0.00884622],\n",
      "       [ 0.00881318,  0.01709573,  0.00050034, -0.00404677]]), 'b1': array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]]), 'W2': array([[-0.0054536 , -0.01546477,  0.00982367, -0.01101068],\n",
      "       [-0.01185047, -0.0020565 ,  0.01486148,  0.00236716],\n",
      "       [-0.01023785, -0.00712993,  0.00625245, -0.00160513],\n",
      "       [-0.00768836, -0.00230031,  0.00745056,  0.01976111],\n",
      "       [-0.01244123, -0.00626417, -0.00803766, -0.02419083],\n",
      "       [-0.00923792, -0.01023876,  0.01123978, -0.00131914]]), 'b2': array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]]), 'W3': array([[-0.01623285,  0.00646675, -0.00356271, -0.01743141, -0.0059665 ,\n",
      "        -0.00588594]]), 'b3': array([[0.]])}\n"
     ]
    }
   ],
   "source": [
    "a = initialize_parameters_deep([4,4,6,1])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba11e619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52cef472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "p = [2,3,4,5,6,7,7,8,8]\n",
    "a= len(p)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89504607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bea6106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10]]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2,3,4]])\n",
    "b = np.array([1,2,3,4])\n",
    "c = np.array([[1,1,1,1]])\n",
    "d = np.array([1,1,1,1])\n",
    "e = np.dot(a,c.T)\n",
    "f = np.dot(b,d)\n",
    "print(e)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0f0cd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((1, 2, 3), 4)\n",
      "((5, 6, 3), 8)\n"
     ]
    }
   ],
   "source": [
    "a = [((1,2,3),4),((5,6,3),8)]\n",
    "b,c = a\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "152ec168",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m [((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m),\u001b[38;5;241m4\u001b[39m)]\n\u001b[1;32m----> 2\u001b[0m b,c \u001b[38;5;241m=\u001b[39m a\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(b)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(c)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "a = [((1,2,3),4)]\n",
    "b,c = a\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d7ccde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\AA66\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Users\\AA66\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Users\\AA66\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"D:\\Users\\AA66\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\AA66\\AppData\\Local\\Temp\\ipykernel_6264\\892423216.py\", line 9, in wave_equation_loss  *\n        t = y_true[:, 1]\n\n    ValueError: slice index 1 of dimension 1 out of bounds. for '{{node wave_equation_loss/strided_slice_1}} = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=1, ellipsis_mask=0, end_mask=1, new_axis_mask=0, shrink_axis_mask=2](ExpandDims, wave_equation_loss/strided_slice_1/stack, wave_equation_loss/strided_slice_1/stack_1, wave_equation_loss/strided_slice_1/stack_2)' with input shapes: [?,1], [2], [2], [2] and with computed input tensors: input[1] = <0 1>, input[2] = <0 2>, input[3] = <1 1>.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39mwave_equation_loss)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(input_data, u\u001b[38;5;241m.\u001b[39mflatten(), epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# 预测波动量\u001b[39;00m\n\u001b[0;32m     48\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(np\u001b[38;5;241m.\u001b[39mvstack([X\u001b[38;5;241m.\u001b[39mflatten(), T\u001b[38;5;241m.\u001b[39mflatten()])\u001b[38;5;241m.\u001b[39mT)\n",
      "File \u001b[1;32mD:\\Users\\AA66\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileslsntme9.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file_zs85fhp.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__wave_equation_loss\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     10\u001b[0m v \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m     11\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(y_true)[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 12\u001b[0m t \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(y_true)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     13\u001b[0m dy_dx \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mgradients, (ag__\u001b[38;5;241m.\u001b[39mld(y_pred), ag__\u001b[38;5;241m.\u001b[39mld(x)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     14\u001b[0m dy_dt \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mgradients, (ag__\u001b[38;5;241m.\u001b[39mld(y_pred), ag__\u001b[38;5;241m.\u001b[39mld(t)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"D:\\Users\\AA66\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\AA66\\AppData\\Local\\Temp\\ipykernel_6264\\892423216.py\", line 9, in wave_equation_loss  *\n        t = y_true[:, 1]\n\n    ValueError: slice index 1 of dimension 1 out of bounds. for '{{node wave_equation_loss/strided_slice_1}} = StridedSlice[Index=DT_INT32, T=DT_FLOAT, begin_mask=1, ellipsis_mask=0, end_mask=1, new_axis_mask=0, shrink_axis_mask=2](ExpandDims, wave_equation_loss/strided_slice_1/stack, wave_equation_loss/strided_slice_1/stack_1, wave_equation_loss/strided_slice_1/stack_2)' with input shapes: [?,1], [2], [2], [2] and with computed input tensors: input[1] = <0 1>, input[2] = <0 2>, input[3] = <1 1>.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 定义波动方程的损失函数\n",
    "def wave_equation_loss(y_true, y_pred):\n",
    "    v = 0.5\n",
    "    x = y_true[:, 0]\n",
    "    t = y_true[:, 1]\n",
    "\n",
    "    # 计算预测值的导数\n",
    "    dy_dx = tf.gradients(y_pred, x)[0]\n",
    "    dy_dt = tf.gradients(y_pred, t)[0]\n",
    "\n",
    "    if dy_dx is None or dy_dt is None:\n",
    "        return 0.0  # 返回一个较小的损失值\n",
    "    # 计算损失函数\n",
    "    loss = tf.reduce_mean(tf.square(dy_dt - v**2 * dy_dx))\n",
    "    return loss\n",
    "\n",
    "# 生成训练数据\n",
    "x = np.linspace(0, 1, num=100)\n",
    "t = np.linspace(0, 1, num=100)\n",
    "X, T = np.meshgrid(x, t)\n",
    "u = np.sin(2 * np.pi * X) * np.exp(-T)\n",
    "\n",
    "# 将 X 和 T 转换为形状为 (N^2, 1) 的向量\n",
    "x_vec = X.flatten().reshape(-1, 1)\n",
    "t_vec = T.flatten().reshape(-1, 1)\n",
    "\n",
    "# 将 x_vec 和 t_vec 水平拼接，形成形状为 (N^2, 2) 的数组\n",
    "input_data = np.hstack([x_vec, t_vec])\n",
    "\n",
    "# 构建深度学习模型\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(2,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss=wave_equation_loss)\n",
    "\n",
    "# 训练模型\n",
    "model.fit(input_data, u.flatten(), epochs=10)\n",
    "\n",
    "# 预测波动量\n",
    "predictions = model.predict(np.vstack([X.flatten(), T.flatten()]).T)\n",
    "\n",
    "# 可视化结果\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(X, T, predictions.reshape(X.shape), cmap='viridis')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('t')\n",
    "ax.set_zlabel('u')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "851e867a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "a = [((1,2,3),4),((4,6,7,8),9)]\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c855e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_planar_dataset():\n",
    "    np.random.seed(1)\n",
    "    m = 400 # number of examples\n",
    "    N = int(m/2) # number of points per class\n",
    "    D = 2 # dimensionality\n",
    "    X = np.zeros((m,D)) # data matrix where each row is a single example\n",
    "    Y = np.zeros((m,1), dtype='uint8') # labels vector (0 for red, 1 for blue)\n",
    "    a = 4 # maximum ray of the flower\n",
    "\n",
    "    for j in range(2):\n",
    "        ix = range(N*j,N*(j+1))\n",
    "        t = np.linspace(j*3.12,(j+1)*3.12,N) + np.random.randn(N)*0.2 # theta\n",
    "        r = a*np.sin(4*t) + np.random.randn(N)*0.2 # radius\n",
    "        X[ix] = np.c_[r*np.sin(t), r*np.cos(t)]\n",
    "        Y[ix] = j\n",
    "        \n",
    "    X = X.T\n",
    "    Y = Y.T\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aed8e7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(2, 400)\n"
     ]
    }
   ],
   "source": [
    "X, Y = load_planar_dataset()\n",
    "print(type(X))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e00a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0a5365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
